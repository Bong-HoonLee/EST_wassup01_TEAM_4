{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### numerical만 포함하기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df_origin_trn = pd.read_csv('/home/sangjun/work/data/HN__4_8__19__train.csv') #임시 -csv직접 올려서 사용함\n",
    "df_origin_tst = pd.read_csv('/home/sangjun/work/data/HN__2020__19__selected.csv') # 2020년도만 분리한 테스트셋 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = [\"age\",\n",
    "\"ainc\",\n",
    "\"HE_PLS_15\",\n",
    "\"HE_PLS_30\",\n",
    "\"HE_mPLS\",\n",
    "\"HE_sbp\",\n",
    "\"HE_dbp\",\n",
    "\"HE_ht\",\n",
    "\"HE_wt\",\n",
    "\"HE_wc\",\n",
    "\"HE_glu\",\n",
    "\"HE_HbA1c\",\n",
    "\"HE_insulin\",\n",
    "\"HE_chol\",\n",
    "\"HE_HDL_st2\",\n",
    "\"HE_TG\",\n",
    "\"HE_LDL_drct\",\n",
    "\"HE_ast\",\n",
    "\"HE_alt\",\n",
    "\"HE_HB\",\n",
    "\"HE_HCT\",\n",
    "\"HE_BUN\",\n",
    "\"HE_crea\",\n",
    "\"HE_WBC\",\n",
    "\"HE_RBC\",\n",
    "\"HE_Bplt\",\n",
    "\"HE_Uacid\",\n",
    "\"HE_Uph\",\n",
    "\"HE_Usg\",\n",
    "\"HE_Ucrea\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_related =[\"BP_PHQ_1\",\n",
    "\"BP_PHQ_2\",\n",
    "\"BP_PHQ_3\",\n",
    "\"BP_PHQ_4\",\n",
    "\"BP_PHQ_5\",\n",
    "\"BP_PHQ_6\",\n",
    "\"BP_PHQ_7\",\n",
    "\"BP_PHQ_8\",\n",
    "\"BP_PHQ_9\",\n",
    "\"mh_PHQ_S\",\n",
    "\"BP6_10\",\n",
    "\"BP6_31\",\n",
    "\"DF2_pr\",\n",
    "\"DF2_pt\",\n",
    "\"BP1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(87986, 125)\n",
      "(6133, 125)\n"
     ]
    }
   ],
   "source": [
    "print(df_origin_trn.shape)\n",
    "print(df_origin_tst.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DF2_pt 변수의 고려\\ndepressed == 0 & mh_PHQ_S != NaN & DF2_pr ==1: \\n치료 여부를 파악해서 고려해주어야 함'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TODO \n",
    "\"\"\"DF2_pt 변수의 고려\n",
    "depressed == 0 & mh_PHQ_S != NaN & DF2_pr ==1: \n",
    "치료 여부를 파악해서 고려해주어야 함\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def manual_preprocess(df:pd.DataFrame, num_features, y_related):\n",
    "    # 1) 9, 99, 999 인 녀석들(모름/무응답) null 처리\n",
    "    df = df.replace([9, 99, 999, 9999], np.nan, inplace=False)\n",
    "\n",
    "    # 2) mh_PHQ_S 는 null값인데, 각 문항 응답인 BP_PHQ_1 ~ 9의 값이 있는 경우, 더해서 mh_PHQ_S에 넣어주기\n",
    "    cond = df[\"BP_PHQ_1\"].notna() & \\\n",
    "            df[\"BP_PHQ_2\"].notna() & \\\n",
    "            df[\"BP_PHQ_3\"].notna() & \\\n",
    "            df[\"BP_PHQ_4\"].notna() & \\\n",
    "            df[\"BP_PHQ_5\"].notna() & \\\n",
    "            df[\"BP_PHQ_6\"].notna() & \\\n",
    "            df[\"BP_PHQ_7\"].notna() & \\\n",
    "            df[\"BP_PHQ_8\"].notna() & \\\n",
    "            df[\"BP_PHQ_9\"].notna()\n",
    "    \n",
    "    a = df[df[\"mh_PHQ_S\"].isnull() & cond][[\"BP_PHQ_1\", \"BP_PHQ_2\", \"BP_PHQ_3\", \"BP_PHQ_4\", \"BP_PHQ_5\", \"BP_PHQ_6\", \"BP_PHQ_7\", \"BP_PHQ_8\", \"BP_PHQ_9\"]]\n",
    "    b = a[a <= 3].sum(axis=1)\n",
    "    b[b >= 1] #125\n",
    "\n",
    "    df['mh_PHQ_S'] = b[b >=1]\n",
    "\n",
    "    # 3) 결측값 처리 1 - row 기준\n",
    "    threshold = 0.3 # threshold for null proportion\n",
    "    null_percent = df.isnull().mean(axis = 1) # 각 행에 대한 결측값 비율 계산\n",
    "    df = df[null_percent < threshold]\n",
    "    \n",
    "    # 4) 변수 생성 `depressed` \n",
    "    cond1 = df['mh_PHQ_S'] >= 10 # mh_PHQ_S - total score \n",
    "    cond2 = df['BP_PHQ_9'].isin([1, 2, 3]) # person who chose 1, 2, 3 in 9th question \n",
    "    cond3 = df['BP6_10'] == 1 \n",
    "    cond4 = df['BP6_31'] == 1\n",
    "    cond5 = (df['DF2_pr'] == 1) & (df['mh_PHQ_S'].isna())\n",
    "\n",
    "    df[cond1 | cond2 | cond3 | cond4 | cond5].drop_duplicates()\n",
    " \n",
    "    df.loc[cond1 | cond2 | cond3 | cond4 | cond5, 'depressed'] = 1 # 조건 중 하나 이상을 만족하는 행에 'depressed' 변수에 1 값 \n",
    "    df.loc[~(cond1 | cond2 | cond3 | cond4 | cond5), 'depressed'] = 0 # 조건 중 하나라도 만족하지 않는 행에 0 값\n",
    "\n",
    "    # 5) 학습에 방해가 될 수 있는 그룹 제거 (우울증에 관한 정보가 없는 경우)\n",
    "    df.drop(df[df['DF2_pr'].isna() & df['mh_PHQ_S'].isna()].index, inplace=True)\n",
    "    df = df[(df['DF2_pr'] != 8 |  ~df['mh_PHQ_S'].isna())]\n",
    "\n",
    "    # 6) 결측값 처리 2 - columns 기준\n",
    "    threshold = 0.1 # 10% 기준 # TODO 30%로 바꿔보기 \n",
    "    null_percent = df.isnull().mean() # 각 열에 대한 결측값 비율 계산\n",
    "    selected_cols = null_percent[null_percent < threshold].index\n",
    "    df = df[selected_cols]\n",
    "\n",
    "    # 7) y_related 변수를 피쳐에서 제외하기\n",
    "    remained_y = set(df.columns).intersection(set(y_related))\n",
    "    y = df['depressed'] # y 생성\n",
    "    X = df.drop(columns=list(remained_y), inplace=False) # X 생성\n",
    "\n",
    "    # 8) 위의 결측값 처리에서 빠진 column을 각 피쳐 그룹에서 제외하기\n",
    "    num_features = set(df.columns).intersection(set(num_features))\n",
    "#     onehot_features = set(df.columns).intersection(set(onehot_features))\n",
    "#     label_features = set(df.columns).intersection(set(label_features))\n",
    "\n",
    "#     # 9) label features중 비해당(8) 값을 각각 알맞은 값으로 대체하기\n",
    "#     label_ans_8 = [\"DI3_2\", \"BD1_11\", \"BD2_11\", \"BA2_12\", \"BA2_13\", \"BP1\", \"BS3_1\",\"BE3_31\", \"BE5_1\"] # BD2_11 - removed\n",
    "\n",
    "#     # 'DI3_2' 변수의 값이 8인 경우, 해당 값을 0으로 바꾸기\n",
    "#     X['DI3_2'] = X['DI3_2'].apply(lambda x: 3 if x == 8 else x)\n",
    "#     X['BD1_11'] = X['BD1_11'].apply(lambda x: 1 if x == 8 else x)\n",
    "#     # X['BD2_11'] = X['BD2_11'].apply(lambda x: 0 if x == 8 else x)\n",
    "#     X['BA2_12'] = X['BA2_12'].apply(lambda x: 5 if x == 8 else x)\n",
    "#     X['BA2_13'] = X['BA2_13'].apply(lambda x: 5 if x == 8 else x)\n",
    "#     X['BA2_13'] = X['BA2_13'].apply(lambda x: 5 if x == 8 else x)\n",
    "#     # X['BP1'] = X['BP1'].apply(lambda x: 5 if x == 8 else x)\n",
    "#     X['BS3_1'] = X['BS3_1'].apply(lambda x: 0 if x == 8 else x)\n",
    "#     # X['BE3_31'] = X['BE3_31'].apply(lambda x: 5 if x == 88 else x)\n",
    "#     # X['BE5_1'] = X['BE5_1'].apply(lambda x: 5 if x == 88 else x)\n",
    "\n",
    "    print(\"X.shape:\", X.shape)\n",
    "    print(\"y.shape:\", y.shape)\n",
    "\n",
    "    return X, y, list(num_features), list(y_related)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape: (74517, 89)\n",
      "y.shape: (74517,)\n",
      "X.shape: (5226, 99)\n",
      "y.shape: (5226,)\n"
     ]
    }
   ],
   "source": [
    "trn_X, trn_y, num_features, y_related = manual_preprocess(df_origin_trn, num_features, y_related)\n",
    "tst_X, tst_y, num_features, y_related = manual_preprocess(df_origin_tst, num_features, y_related)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5226, 89)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 10) train column과 test column 일치시키기\n",
    "tst_X = tst_X[list(trn_X.columns)]\n",
    "tst_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 임시 -transform\n",
    "def transform(X, y, num_features, y_related):\n",
    "    ### 결측값 처리 3 - fillna: KNN\n",
    "    from sklearn.impute import KNNImputer\n",
    "    from sklearn.impute import SimpleImputer\n",
    "\n",
    "    # 1) num_features 결측값 처리 - KNN\n",
    "    knn_imp = KNNImputer(n_neighbors=5)\n",
    "    X[num_features] = knn_imp.fit_transform(X[num_features])\n",
    "\n",
    "    # # 2) onehot_features, label_features 결측값 처리 - 최빈값(most frequent values)\n",
    "    # freq_imp = SimpleImputer(strategy = \"most_frequent\")\n",
    "    # X[onehot_features] = freq_imp.fit_transform(X[onehot_features])\n",
    "    # X[label_features] = freq_imp.fit_transform(X[label_features])\n",
    "\n",
    "    # transform array(X) to dataframe\n",
    "    df_new = pd.DataFrame(X, columns=X.columns) \n",
    "    df_new.isna().sum().sort_values(ascending = False)\n",
    "\n",
    "    ### 인코딩\n",
    "    # 1. numeric # 1. numeric - scaling \n",
    "    from sklearn.preprocessing import MinMaxScaler \n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    df_new[num_features] = scaler.fit_transform(df_new[num_features])\n",
    "    # # 2. onehot -> onehot 인코딩으로 진행\n",
    "    # df_new = pd.get_dummies(df_new, columns=onehot_features) # sklearn OneHotEncoder 사용도 가능함\n",
    "\n",
    "    ### 샘플링\n",
    "    # under sampling.  OVER 만 하기엔 너무 많이 생성해야해서 under 선수행\n",
    "    from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "    X = df_new\n",
    "    rus = RandomUnderSampler(sampling_strategy=0.5, random_state=42)\n",
    "    X_under, y_under = rus.fit_resample(X, y)\n",
    "    X_under.shape, y_under.shape\n",
    "\n",
    "    # over sampling\n",
    "    from imblearn.over_sampling import SMOTE\n",
    "\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_over, y_over = smote.fit_resample(X_under, y_under)\n",
    "\n",
    "    X_over.shape, y_over.shape\n",
    "\n",
    "    return X_over, y_over\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_355474/1080958715.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[num_features] = knn_imp.fit_transform(X[num_features])\n"
     ]
    }
   ],
   "source": [
    "X_over, y_over = transform(trn_X[num_features], trn_y, num_features, y_related)\n",
    "#override\n",
    "X_over = trn_X[num_features]\n",
    "y_over = trn_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_355474/1080958715.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[num_features] = knn_imp.fit_transform(X[num_features])\n"
     ]
    }
   ],
   "source": [
    "X_test_over, y_test_over = transform(tst_X[num_features], tst_y, num_features, y_related)\n",
    "#override\n",
    "X_test_over = tst_X[num_features]\n",
    "y_test_over = tst_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((74517, 22), (74517,))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_over.shape, y_over.shape,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5226, 22), (5226,))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_over.shape, y_test_over.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Cannot save file into a non-existent directory: '../data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m/home/sangjun/work/EST_wassup01_TEAM_4/archive/dataframe_20231206_numeric_only.ipynb Cell 15\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22455354536f6674227d/home/sangjun/work/EST_wassup01_TEAM_4/archive/dataframe_20231206_numeric_only.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m X_over\u001b[39m.\u001b[39;49mto_csv(\u001b[39m'\u001b[39;49m\u001b[39m../data/HN_X_numerical_231208_wo_transform.csv\u001b[39;49m\u001b[39m'\u001b[39;49m, index\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22455354536f6674227d/home/sangjun/work/EST_wassup01_TEAM_4/archive/dataframe_20231206_numeric_only.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m y_over\u001b[39m.\u001b[39mto_csv(\u001b[39m'\u001b[39m\u001b[39m../data/HN_y_numerical_231208.csv\u001b[39m\u001b[39m'\u001b[39m, index\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/yes/envs/MathAI/lib/python3.10/site-packages/pandas/core/generic.py:3902\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[1;32m   3891\u001b[0m df \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m, ABCDataFrame) \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mto_frame()\n\u001b[1;32m   3893\u001b[0m formatter \u001b[39m=\u001b[39m DataFrameFormatter(\n\u001b[1;32m   3894\u001b[0m     frame\u001b[39m=\u001b[39mdf,\n\u001b[1;32m   3895\u001b[0m     header\u001b[39m=\u001b[39mheader,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3899\u001b[0m     decimal\u001b[39m=\u001b[39mdecimal,\n\u001b[1;32m   3900\u001b[0m )\n\u001b[0;32m-> 3902\u001b[0m \u001b[39mreturn\u001b[39;00m DataFrameRenderer(formatter)\u001b[39m.\u001b[39;49mto_csv(\n\u001b[1;32m   3903\u001b[0m     path_or_buf,\n\u001b[1;32m   3904\u001b[0m     lineterminator\u001b[39m=\u001b[39;49mlineterminator,\n\u001b[1;32m   3905\u001b[0m     sep\u001b[39m=\u001b[39;49msep,\n\u001b[1;32m   3906\u001b[0m     encoding\u001b[39m=\u001b[39;49mencoding,\n\u001b[1;32m   3907\u001b[0m     errors\u001b[39m=\u001b[39;49merrors,\n\u001b[1;32m   3908\u001b[0m     compression\u001b[39m=\u001b[39;49mcompression,\n\u001b[1;32m   3909\u001b[0m     quoting\u001b[39m=\u001b[39;49mquoting,\n\u001b[1;32m   3910\u001b[0m     columns\u001b[39m=\u001b[39;49mcolumns,\n\u001b[1;32m   3911\u001b[0m     index_label\u001b[39m=\u001b[39;49mindex_label,\n\u001b[1;32m   3912\u001b[0m     mode\u001b[39m=\u001b[39;49mmode,\n\u001b[1;32m   3913\u001b[0m     chunksize\u001b[39m=\u001b[39;49mchunksize,\n\u001b[1;32m   3914\u001b[0m     quotechar\u001b[39m=\u001b[39;49mquotechar,\n\u001b[1;32m   3915\u001b[0m     date_format\u001b[39m=\u001b[39;49mdate_format,\n\u001b[1;32m   3916\u001b[0m     doublequote\u001b[39m=\u001b[39;49mdoublequote,\n\u001b[1;32m   3917\u001b[0m     escapechar\u001b[39m=\u001b[39;49mescapechar,\n\u001b[1;32m   3918\u001b[0m     storage_options\u001b[39m=\u001b[39;49mstorage_options,\n\u001b[1;32m   3919\u001b[0m )\n",
      "File \u001b[0;32m~/yes/envs/MathAI/lib/python3.10/site-packages/pandas/io/formats/format.py:1152\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[0;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[1;32m   1131\u001b[0m     created_buffer \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m   1133\u001b[0m csv_formatter \u001b[39m=\u001b[39m CSVFormatter(\n\u001b[1;32m   1134\u001b[0m     path_or_buf\u001b[39m=\u001b[39mpath_or_buf,\n\u001b[1;32m   1135\u001b[0m     lineterminator\u001b[39m=\u001b[39mlineterminator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     formatter\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfmt,\n\u001b[1;32m   1151\u001b[0m )\n\u001b[0;32m-> 1152\u001b[0m csv_formatter\u001b[39m.\u001b[39;49msave()\n\u001b[1;32m   1154\u001b[0m \u001b[39mif\u001b[39;00m created_buffer:\n\u001b[1;32m   1155\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[0;32m~/yes/envs/MathAI/lib/python3.10/site-packages/pandas/io/formats/csvs.py:247\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    244\u001b[0m \u001b[39mCreate the writer & save.\u001b[39;00m\n\u001b[1;32m    245\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    246\u001b[0m \u001b[39m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[0;32m--> 247\u001b[0m \u001b[39mwith\u001b[39;00m get_handle(\n\u001b[1;32m    248\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfilepath_or_buffer,\n\u001b[1;32m    249\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmode,\n\u001b[1;32m    250\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoding,\n\u001b[1;32m    251\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49merrors,\n\u001b[1;32m    252\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompression,\n\u001b[1;32m    253\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstorage_options,\n\u001b[1;32m    254\u001b[0m ) \u001b[39mas\u001b[39;00m handles:\n\u001b[1;32m    255\u001b[0m     \u001b[39m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[1;32m    256\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwriter \u001b[39m=\u001b[39m csvlib\u001b[39m.\u001b[39mwriter(\n\u001b[1;32m    257\u001b[0m         handles\u001b[39m.\u001b[39mhandle,\n\u001b[1;32m    258\u001b[0m         lineterminator\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlineterminator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    263\u001b[0m         quotechar\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mquotechar,\n\u001b[1;32m    264\u001b[0m     )\n\u001b[1;32m    266\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_save()\n",
      "File \u001b[0;32m~/yes/envs/MathAI/lib/python3.10/site-packages/pandas/io/common.py:739\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    737\u001b[0m \u001b[39m# Only for write methods\u001b[39;00m\n\u001b[1;32m    738\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode \u001b[39mand\u001b[39;00m is_path:\n\u001b[0;32m--> 739\u001b[0m     check_parent_directory(\u001b[39mstr\u001b[39;49m(handle))\n\u001b[1;32m    741\u001b[0m \u001b[39mif\u001b[39;00m compression:\n\u001b[1;32m    742\u001b[0m     \u001b[39mif\u001b[39;00m compression \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mzstd\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    743\u001b[0m         \u001b[39m# compression libraries do not like an explicit text-mode\u001b[39;00m\n",
      "File \u001b[0;32m~/yes/envs/MathAI/lib/python3.10/site-packages/pandas/io/common.py:604\u001b[0m, in \u001b[0;36mcheck_parent_directory\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    602\u001b[0m parent \u001b[39m=\u001b[39m Path(path)\u001b[39m.\u001b[39mparent\n\u001b[1;32m    603\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m parent\u001b[39m.\u001b[39mis_dir():\n\u001b[0;32m--> 604\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mOSError\u001b[39;00m(\u001b[39mrf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCannot save file into a non-existent directory: \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mparent\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mOSError\u001b[0m: Cannot save file into a non-existent directory: '../data'"
     ]
    }
   ],
   "source": [
    "X_over.to_csv('/home/sangjun/work/', index=False)\n",
    "y_over.to_csv('/home/sangjun/work/', index=False)\n",
    "\n",
    "# X_test_over.to_csv('../data/HN_X_231206_numerical_wo_transform_test.csv', index=False)\n",
    "# y_test_over.to_csv('../data/HN_y_231206_numerical__test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
