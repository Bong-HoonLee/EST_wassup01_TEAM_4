{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### numerical만 포함하기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df_origin_trn = pd.read_csv('../HN__4_8__19__train.csv') #임시 -csv직접 올려서 사용함\n",
    "df_origin_tst = pd.read_csv('../HN__2020__19__selected.csv') # 2020년도만 분리한 테스트셋 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = [\"age\",\n",
    "\"ainc\",\n",
    "\"HE_PLS_15\",\n",
    "\"HE_PLS_30\",\n",
    "\"HE_mPLS\",\n",
    "\"HE_sbp\",\n",
    "\"HE_dbp\",\n",
    "\"HE_ht\",\n",
    "\"HE_wt\",\n",
    "\"HE_wc\",\n",
    "\"HE_glu\",\n",
    "\"HE_HbA1c\",\n",
    "\"HE_insulin\",\n",
    "\"HE_chol\",\n",
    "\"HE_HDL_st2\",\n",
    "\"HE_TG\",\n",
    "\"HE_LDL_drct\",\n",
    "\"HE_ast\",\n",
    "\"HE_alt\",\n",
    "\"HE_HB\",\n",
    "\"HE_HCT\",\n",
    "\"HE_BUN\",\n",
    "\"HE_crea\",\n",
    "\"HE_WBC\",\n",
    "\"HE_RBC\",\n",
    "\"HE_Bplt\",\n",
    "\"HE_Uacid\",\n",
    "\"HE_Uph\",\n",
    "\"HE_Usg\",\n",
    "\"HE_Ucrea\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_related =[\"BP_PHQ_1\",\n",
    "\"BP_PHQ_2\",\n",
    "\"BP_PHQ_3\",\n",
    "\"BP_PHQ_4\",\n",
    "\"BP_PHQ_5\",\n",
    "\"BP_PHQ_6\",\n",
    "\"BP_PHQ_7\",\n",
    "\"BP_PHQ_8\",\n",
    "\"BP_PHQ_9\",\n",
    "\"mh_PHQ_S\",\n",
    "\"BP6_10\",\n",
    "\"BP6_31\",\n",
    "\"DF2_pr\",\n",
    "\"DF2_pt\",\n",
    "\"BP1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(87986, 125)\n",
      "(6133, 125)\n"
     ]
    }
   ],
   "source": [
    "print(df_origin_trn.shape)\n",
    "print(df_origin_tst.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DF2_pt 변수의 고려\\ndepressed == 0 & mh_PHQ_S != NaN & DF2_pr ==1: \\n치료 여부를 파악해서 고려해주어야 함'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TODO \n",
    "\"\"\"DF2_pt 변수의 고려\n",
    "depressed == 0 & mh_PHQ_S != NaN & DF2_pr ==1: \n",
    "치료 여부를 파악해서 고려해주어야 함\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def manual_preprocess(df:pd.DataFrame, num_features, y_related):\n",
    "    # 1) 9, 99, 999 인 녀석들(모름/무응답) null 처리\n",
    "    df = df.replace([9, 99, 999, 9999], np.nan, inplace=False)\n",
    "\n",
    "    # 2) mh_PHQ_S 는 null값인데, 각 문항 응답인 BP_PHQ_1 ~ 9의 값이 있는 경우, 더해서 mh_PHQ_S에 넣어주기\n",
    "    cond = df[\"BP_PHQ_1\"].notna() & \\\n",
    "            df[\"BP_PHQ_2\"].notna() & \\\n",
    "            df[\"BP_PHQ_3\"].notna() & \\\n",
    "            df[\"BP_PHQ_4\"].notna() & \\\n",
    "            df[\"BP_PHQ_5\"].notna() & \\\n",
    "            df[\"BP_PHQ_6\"].notna() & \\\n",
    "            df[\"BP_PHQ_7\"].notna() & \\\n",
    "            df[\"BP_PHQ_8\"].notna() & \\\n",
    "            df[\"BP_PHQ_9\"].notna()\n",
    "    \n",
    "    a = df[df[\"mh_PHQ_S\"].isnull() & cond][[\"BP_PHQ_1\", \"BP_PHQ_2\", \"BP_PHQ_3\", \"BP_PHQ_4\", \"BP_PHQ_5\", \"BP_PHQ_6\", \"BP_PHQ_7\", \"BP_PHQ_8\", \"BP_PHQ_9\"]]\n",
    "    b = a[a <= 3].sum(axis=1)\n",
    "    b[b >= 1] #125\n",
    "\n",
    "    df['mh_PHQ_S'] = b[b >=1]\n",
    "\n",
    "    # 3) 결측값 처리 1 - row 기준\n",
    "    threshold = 0.3 # threshold for null proportion\n",
    "    null_percent = df.isnull().mean(axis = 1) # 각 행에 대한 결측값 비율 계산\n",
    "    df = df[null_percent < threshold]\n",
    "    \n",
    "    # 4) 변수 생성 `depressed` \n",
    "    cond1 = df['mh_PHQ_S'] >= 10 # mh_PHQ_S - total score \n",
    "    cond2 = df['BP_PHQ_9'].isin([1, 2, 3]) # person who chose 1, 2, 3 in 9th question \n",
    "    cond3 = df['BP6_10'] == 1 \n",
    "    cond4 = df['BP6_31'] == 1\n",
    "    cond5 = (df['DF2_pr'] == 1) & (df['mh_PHQ_S'].isna())\n",
    "\n",
    "    df[cond1 | cond2 | cond3 | cond4 | cond5].drop_duplicates()\n",
    " \n",
    "    df.loc[cond1 | cond2 | cond3 | cond4 | cond5, 'depressed'] = 1 # 조건 중 하나 이상을 만족하는 행에 'depressed' 변수에 1 값 \n",
    "    df.loc[~(cond1 | cond2 | cond3 | cond4 | cond5), 'depressed'] = 0 # 조건 중 하나라도 만족하지 않는 행에 0 값\n",
    "\n",
    "    # 5) 학습에 방해가 될 수 있는 그룹 제거 (우울증에 관한 정보가 없는 경우)\n",
    "    df.drop(df[df['DF2_pr'].isna() & df['mh_PHQ_S'].isna()].index, inplace=True)\n",
    "    df = df[(df['DF2_pr'] != 8 |  ~df['mh_PHQ_S'].isna())]\n",
    "\n",
    "    # 6) 결측값 처리 2 - columns 기준\n",
    "    threshold = 0.1 # 10% 기준 # TODO 30%로 바꿔보기 \n",
    "    null_percent = df.isnull().mean() # 각 열에 대한 결측값 비율 계산\n",
    "    selected_cols = null_percent[null_percent < threshold].index\n",
    "    df = df[selected_cols]\n",
    "\n",
    "    # 7) y_related 변수를 피쳐에서 제외하기\n",
    "    remained_y = set(df.columns).intersection(set(y_related))\n",
    "    y = df['depressed'] # y 생성\n",
    "    X = df.drop(columns=list(remained_y), inplace=False) # X 생성\n",
    "\n",
    "    # 8) 위의 결측값 처리에서 빠진 column을 각 피쳐 그룹에서 제외하기\n",
    "    num_features = set(df.columns).intersection(set(num_features))\n",
    "#     onehot_features = set(df.columns).intersection(set(onehot_features))\n",
    "#     label_features = set(df.columns).intersection(set(label_features))\n",
    "\n",
    "#     # 9) label features중 비해당(8) 값을 각각 알맞은 값으로 대체하기\n",
    "#     label_ans_8 = [\"DI3_2\", \"BD1_11\", \"BD2_11\", \"BA2_12\", \"BA2_13\", \"BP1\", \"BS3_1\",\"BE3_31\", \"BE5_1\"] # BD2_11 - removed\n",
    "\n",
    "#     # 'DI3_2' 변수의 값이 8인 경우, 해당 값을 0으로 바꾸기\n",
    "#     X['DI3_2'] = X['DI3_2'].apply(lambda x: 3 if x == 8 else x)\n",
    "#     X['BD1_11'] = X['BD1_11'].apply(lambda x: 1 if x == 8 else x)\n",
    "#     # X['BD2_11'] = X['BD2_11'].apply(lambda x: 0 if x == 8 else x)\n",
    "#     X['BA2_12'] = X['BA2_12'].apply(lambda x: 5 if x == 8 else x)\n",
    "#     X['BA2_13'] = X['BA2_13'].apply(lambda x: 5 if x == 8 else x)\n",
    "#     X['BA2_13'] = X['BA2_13'].apply(lambda x: 5 if x == 8 else x)\n",
    "#     # X['BP1'] = X['BP1'].apply(lambda x: 5 if x == 8 else x)\n",
    "#     X['BS3_1'] = X['BS3_1'].apply(lambda x: 0 if x == 8 else x)\n",
    "#     # X['BE3_31'] = X['BE3_31'].apply(lambda x: 5 if x == 88 else x)\n",
    "#     # X['BE5_1'] = X['BE5_1'].apply(lambda x: 5 if x == 88 else x)\n",
    "\n",
    "    print(\"X.shape:\", X.shape)\n",
    "    print(\"y.shape:\", y.shape)\n",
    "\n",
    "    return X, y, num_features, y_related"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape: (74517, 89)\n",
      "y.shape: (74517,)\n",
      "X.shape: (5226, 99)\n",
      "y.shape: (5226,)\n"
     ]
    }
   ],
   "source": [
    "trn_X, trn_y, num_features, y_related = manual_preprocess(df_origin_trn, num_features, y_related)\n",
    "tst_X, tst_y, num_features, y_related = manual_preprocess(df_origin_tst, num_features, y_related)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5226, 89)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 10) train column과 test column 일치시키기\n",
    "tst_X = tst_X[list(trn_X.columns)]\n",
    "tst_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 임시 -transform\n",
    "def transform(X, y, num_features, y_related):\n",
    "    ### 결측값 처리 3 - fillna: KNN\n",
    "    from sklearn.impute import KNNImputer\n",
    "    from sklearn.impute import SimpleImputer\n",
    "\n",
    "    # 1) num_features 결측값 처리 - KNN\n",
    "    knn_imp = KNNImputer(n_neighbors=5)\n",
    "    X[num_features] = knn_imp.fit_transform(X[num_features])\n",
    "\n",
    "    # # 2) onehot_features, label_features 결측값 처리 - 최빈값(most frequent values)\n",
    "    # freq_imp = SimpleImputer(strategy = \"most_frequent\")\n",
    "    # X[onehot_features] = freq_imp.fit_transform(X[onehot_features])\n",
    "    # X[label_features] = freq_imp.fit_transform(X[label_features])\n",
    "\n",
    "    # transform array(X) to dataframe\n",
    "    df_new = pd.DataFrame(X, columns=X.columns) \n",
    "    df_new.isna().sum().sort_values(ascending = False)\n",
    "\n",
    "    ### 인코딩\n",
    "    # 1. numeric # 1. numeric - scaling \n",
    "    from sklearn.preprocessing import MinMaxScaler \n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    df_new[num_features] = scaler.fit_transform(df_new[num_features])\n",
    "    # # 2. onehot -> onehot 인코딩으로 진행\n",
    "    # df_new = pd.get_dummies(df_new, columns=onehot_features) # sklearn OneHotEncoder 사용도 가능함\n",
    "\n",
    "    ### 샘플링\n",
    "    # under sampling.  OVER 만 하기엔 너무 많이 생성해야해서 under 선수행\n",
    "    from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "    X = df_new\n",
    "    rus = RandomUnderSampler(sampling_strategy=0.1, random_state=42)\n",
    "    X_under, y_under = rus.fit_resample(X, y)\n",
    "    X_under.shape, y_under.shape\n",
    "\n",
    "    # over sampling\n",
    "    from imblearn.over_sampling import SMOTE\n",
    "\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_over, y_over = smote.fit_resample(X_under, y_under)\n",
    "\n",
    "    X_over.shape, y_over.shape\n",
    "\n",
    "    return X_over, y_over\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jiwoo/miniconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:767: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "/home/jiwoo/miniconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/home/jiwoo/miniconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/home/jiwoo/miniconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:767: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "/home/jiwoo/miniconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/home/jiwoo/miniconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n"
     ]
    }
   ],
   "source": [
    "X_over, y_over = transform(trn_X, trn_y, list(num_features), list(y_related))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_over.to_csv('../data/HN_X_231206.csv', index=False)\n",
    "# y_over.to_csv('../data/HN_y_231206.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
