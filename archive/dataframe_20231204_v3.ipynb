{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3y/hj83hdwn2nn49jp7jks64t480000gn/T/ipykernel_34074/1267087970.py:4: DtypeWarning: Columns (205) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('../data/HN__4_8__19__selected.csv')\n"
     ]
    }
   ],
   "source": [
    "## 9, 99, 999 애들 null 처리하고 데이터 얼마나 빠지는지 체크\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../data/HN__4_8__19__selected.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BP_PHQ_1  BP_PHQ_2  BP_PHQ_3  BP_PHQ_4  BP_PHQ_5  BP_PHQ_6  BP_PHQ_7  BP_PHQ_8  BP_PHQ_9\n",
       "9.0       9.0       9.0       9.0       9.0       9.0       9.0       9.0       9.0         1567\n",
       "0.0       0.0       0.0       9.0       0.0       0.0       0.0       0.0       0.0            9\n",
       "          9.0       0.0       0.0       0.0       0.0       0.0       0.0       0.0            5\n",
       "          0.0       0.0       0.0       0.0       9.0       0.0       0.0       0.0            4\n",
       "1.0       9.0       9.0       9.0       9.0       9.0       9.0       9.0       9.0            3\n",
       "                                                                                            ... \n",
       "0.0       1.0       2.0       1.0       0.0       1.0       9.0       9.0       1.0            1\n",
       "                    1.0       9.0       0.0       0.0       0.0       0.0       1.0            1\n",
       "                              2.0       9.0       2.0       0.0       0.0       0.0            1\n",
       "                    0.0       0.0       0.0       0.0       9.0       9.0       1.0            1\n",
       "          9.0       9.0       9.0       0.0       0.0       0.0       0.0       0.0            1\n",
       "Name: count, Length: 146, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y라벨 결측치\n",
    "# mh_PHQ_S    9074\n",
    "# DF2_pr      1629\n",
    "# BP_PHQ_1    1629\n",
    "# BP_PHQ_2    1629\n",
    "# BP_PHQ_3    1629\n",
    "# BP_PHQ_4    1629\n",
    "# BP_PHQ_5    1629\n",
    "# BP_PHQ_6    1629\n",
    "# BP_PHQ_7    1629\n",
    "# BP_PHQ_8    1629\n",
    "# BP_PHQ_9    1629\n",
    "# dtype: int64\n",
    "\n",
    "#TODO 결측 채워도 되는지 나중에 확인할것\n",
    "# 총점: 0~27점\n",
    "\n",
    "cond = df[\"BP_PHQ_1\"].notna() & \\\n",
    "        df[\"BP_PHQ_2\"].notna() & \\\n",
    "        df[\"BP_PHQ_3\"].notna() & \\\n",
    "        df[\"BP_PHQ_4\"].notna() & \\\n",
    "        df[\"BP_PHQ_5\"].notna() & \\\n",
    "        df[\"BP_PHQ_6\"].notna() & \\\n",
    "        df[\"BP_PHQ_7\"].notna() & \\\n",
    "        df[\"BP_PHQ_8\"].notna() & \\\n",
    "        df[\"BP_PHQ_9\"].notna()\n",
    "\n",
    "df[df[\"mh_PHQ_S\"].isnull() & cond][[\"BP_PHQ_1\", \"BP_PHQ_2\", \"BP_PHQ_3\", \"BP_PHQ_4\", \"BP_PHQ_5\", \"BP_PHQ_6\", \"BP_PHQ_7\", \"BP_PHQ_8\", \"BP_PHQ_9\"]].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = df[df[\"mh_PHQ_S\"].isnull() & cond][[\"BP_PHQ_1\", \"BP_PHQ_2\", \"BP_PHQ_3\", \"BP_PHQ_4\", \"BP_PHQ_5\", \"BP_PHQ_6\", \"BP_PHQ_7\", \"BP_PHQ_8\", \"BP_PHQ_9\"]]\n",
    "\n",
    "b = a[a <= 3].sum(axis=1)\n",
    "b[b >= 1] #125\n",
    "\n",
    "df['mh_PHQ_S'] = b[b >=1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LQ4_24</th>\n",
       "      <th>N_DT_DS</th>\n",
       "      <th>N_DUSUAL</th>\n",
       "      <th>N_DAY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>수요일</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>수요일</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>화요일</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>화요일</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94114</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>È­</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94115</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>È­</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94116</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>¼ö</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94117</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>¼ö</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94118</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>¼ö</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>94119 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      LQ4_24 N_DT_DS N_DUSUAL N_DAY\n",
       "0        NaN     NaN      3.0   수요일\n",
       "1        NaN     NaN      2.0   수요일\n",
       "2        NaN     NaN      1.0   화요일\n",
       "3        NaN     NaN      1.0   화요일\n",
       "4        NaN     NaN      NaN   NaN\n",
       "...      ...     ...      ...   ...\n",
       "94114    NaN     NaN      2.0    È­\n",
       "94115    NaN     NaN      3.0    È­\n",
       "94116    NaN     NaN      2.0    ¼ö\n",
       "94117    NaN     NaN      3.0    ¼ö\n",
       "94118    NaN     NaN      2.0    ¼ö\n",
       "\n",
       "[94119 rows x 4 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select_dtypes(include=['object']).columns\n",
    "\n",
    "\n",
    "####### 얘네 빼도 되는지 확인 - object 타입인 녀석들 ####\n",
    "df[['LQ4_24', 'N_DT_DS', 'N_DUSUAL', 'N_DAY']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### 9, 99, 999 인 녀석들 null 처리\n",
    "import numpy as np\n",
    "df = df.replace([9, 99, 999, 9999], np.nan, inplace=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "depressed\n",
       "0.0    82952\n",
       "1.0     1165\n",
       "dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# row 기준 \n",
    "threshold = 0.3 # threshold for null proportion\n",
    "null_percent = df.isnull().mean(axis = 1) # 각 행에 대한 결측값 비율 계산\n",
    "df = df[null_percent < threshold]\n",
    "\n",
    "# Define depression (dependent variable)\n",
    "cond1 = df['mh_PHQ_S'] >= 10 # total score \n",
    "cond2 = df['BP_PHQ_9'].isin([1, 2, 3]) # person who chose 1, 2, 3 in 9th question\n",
    "\n",
    "df[cond1 | cond2].drop_duplicates() # person with cond1 or cond2\n",
    "\n",
    "\n",
    "# Create a new variable 'depressed' \n",
    "df.loc[cond1 | cond2, 'depressed'] = 1 # 두 조건 중 하나 이상을 만족하는 행에 'depressed' 변수에 1 값 \n",
    "df.loc[~(cond1 | cond2), 'depressed'] = 0 # 두 조건 중 하나라도 만족하지 않는 행에 0 값\n",
    "\n",
    "\n",
    "# Remove people who might be depressed\n",
    "# DF2_pr == 8 (never been diagnosed by doctor) & mh_PHQ_S == NaN) 인 경우를 제외하려면?\n",
    "# DF2_pr != 8 or mh_PHQ != NaN (전부 다 ~ 취하기)\n",
    "df = df[(df['DF2_pr'] != 8 |  ~df['mh_PHQ_S'].isna())]\n",
    "df.shape\n",
    "\n",
    "\n",
    "# Remove columns if percentage of NaN exceeds 0.1\n",
    "threshold = 0.3 # 이거로 하나, 0.1로 하나 큰 차이 x\n",
    "threshold = 0.1 \n",
    "\n",
    "null_percent = df.isnull().mean() # 각 열에 대한 결측값 비율 계산\n",
    "selected_cols = null_percent[null_percent < threshold].index\n",
    "df = df[selected_cols]\n",
    "df.shape # (20492, 314)\n",
    "\n",
    "\n",
    "df.groupby('depressed').size()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO fillna\n",
    "#TODO scaling\n",
    "#TODO over, under sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "\n",
    "mh_PHQ_S_col = df8[\"mh_PHQ_S\"]\n",
    "\n",
    "\n",
    "imputer = KNNImputer(n_neighbors=20)  \n",
    "mh_PHQ_S_col_filled = imputer.fit_transform(mh_PHQ_S_col.values.reshape(-1, 1))\n",
    "\n",
    "\n",
    "df8[\"mh_PHQ_S\"] = mh_PHQ_S_col_filled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# df2 = df.dropna()\n",
    "# \"depressed\" in df2.columns # True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39617, 157)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "depressed\n",
       "0.0    39004\n",
       "1.0      613\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.groupby('depressed').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape Counter({0.0: 39004, 1.0: 613})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ijong-won/miniconda3/envs/torch-nightly/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Users/ijong-won/miniconda3/envs/torch-nightly/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/Users/ijong-won/miniconda3/envs/torch-nightly/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Users/ijong-won/miniconda3/envs/torch-nightly/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/Users/ijong-won/miniconda3/envs/torch-nightly/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Users/ijong-won/miniconda3/envs/torch-nightly/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/Users/ijong-won/miniconda3/envs/torch-nightly/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Users/ijong-won/miniconda3/envs/torch-nightly/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/Users/ijong-won/miniconda3/envs/torch-nightly/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Users/ijong-won/miniconda3/envs/torch-nightly/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/Users/ijong-won/miniconda3/envs/torch-nightly/lib/python3.11/site-packages/sklearn/utils/validation.py:767: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "/Users/ijong-won/miniconda3/envs/torch-nightly/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Users/ijong-won/miniconda3/envs/torch-nightly/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled dataset shape Counter({0.0: 39004, 1.0: 39004})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3y/hj83hdwn2nn49jp7jks64t480000gn/T/ipykernel_34074/2805469819.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  temp['y_label'] = y_res\n"
     ]
    }
   ],
   "source": [
    "#TODO 오버샘플링 or 언더\n",
    "\n",
    "from collections import Counter\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# X, y = make_classification(n_classes=2, class_sep=2,\n",
    "#                            weights=[0.1, 0.9], n_informative=3, n_redundant=1, \n",
    "#                            flip_y=0, n_features=20, n_clusters_per_class=1, \n",
    "#                            n_samples=1000, random_state=10)\n",
    "\n",
    "\n",
    "######\n",
    "X = df2.drop('depressed', axis = 1)\n",
    "y = df2['depressed']\n",
    "\n",
    "# 원본 데이터셋의 클래스 분포 확인\n",
    "print('Original dataset shape %s' % Counter(y))\n",
    "\n",
    "# SMOTE 적용\n",
    "smote = SMOTE(random_state=42)\n",
    "X_res, y_res = smote.fit_resample(X, y)\n",
    "\n",
    "# 오버샘플링 후의 클래스 분포 확인\n",
    "print('Resampled dataset shape %s' % Counter(y_res))\n",
    "\n",
    "# TODO 데이터 시각화\n",
    "temp = pd.DataFrame(X_res)\n",
    "temp['y_label'] = y_res\n",
    "\n",
    "# plt.scatter(temp[temp['label']==0], temp[temp['label']==0], label='0')\n",
    "# plt.scatter(temp[temp['label']==1], temp[temp['label']==1], label='1')\n",
    "# plt.title(\"SMOTE - Over-sampled Data\")\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(78008, 157)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp.drop('y_label', axis=1).to_csv('../data/HN_train_X.csv', index=False)\n",
    "# temp[\"y_label\"].to_csv('../data/HN_train_y.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-nightly",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
