{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 이후 csv 생성을 위한 EDA 작업\n",
    "- transform (결측값, 인코딩 작업) 전까지 처리해서 csv 생성하기\n",
    "- 변경 사항: `depressed` 생성 조건 추가\n",
    "    - `depressed` == 1 if:\n",
    "    - ['mh_PHQ_S'] >= 10 or \n",
    "    - ['BP_PHQ_9'].isin([1, 2, 3]) or\n",
    "    - **['BP6_10'] == 1 or  # 1년간 자살 생각 여부**\n",
    "    - **['BP6_31'] == 1 or # 1년간 자살 시도 여부**\n",
    "    - **['DF2_pr'] == 1 & ['mh_PHQ_S'] == NaN** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df_origin_trn = pd.read_csv('../HN__4_8__19__train.csv') #임시 -csv직접 올려서 사용함\n",
    "df_origin_tst = pd.read_csv('../HN__2020__19__selected.csv') # 2020년도만 분리한 테스트셋 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = [\"age\",\n",
    "\"ainc\",\n",
    "\"HE_PLS_15\",\n",
    "\"HE_PLS_30\",\n",
    "\"HE_mPLS\",\n",
    "\"HE_sbp\",\n",
    "\"HE_dbp\",\n",
    "\"HE_ht\",\n",
    "\"HE_wt\",\n",
    "\"HE_wc\",\n",
    "\"HE_glu\",\n",
    "\"HE_HbA1c\",\n",
    "\"HE_insulin\",\n",
    "\"HE_chol\",\n",
    "\"HE_HDL_st2\",\n",
    "\"HE_TG\",\n",
    "\"HE_LDL_drct\",\n",
    "\"HE_ast\",\n",
    "\"HE_alt\",\n",
    "\"HE_HB\",\n",
    "\"HE_HCT\",\n",
    "\"HE_BUN\",\n",
    "\"HE_crea\",\n",
    "\"HE_WBC\",\n",
    "\"HE_RBC\",\n",
    "\"HE_Bplt\",\n",
    "\"HE_Uacid\",\n",
    "\"HE_Uph\",\n",
    "\"HE_Usg\",\n",
    "\"HE_Ucrea\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onehot_features = [\"region\",\n",
    "\"sex\",\n",
    "\"occp\",\n",
    "\"marri_1\",\n",
    "\"tins\",\n",
    "\"npins\",\n",
    "\"D_2_1\",\n",
    "\"DI1_pr\",\n",
    "\"DI1_pt\",\n",
    "\"DI2_pr\",\n",
    "\"DI2_pt\",\n",
    "\"DI3_pr\",\n",
    "\"DI3_pt\",\n",
    "\"DJ4_pr\",\n",
    "\"DJ4_pt\",\n",
    "\"DE1_pr\",\n",
    "\"DE1_pt\",\n",
    "\"BH9_11\",\n",
    "\"BH1\",\n",
    "\"BH2_61\",\n",
    "\"LQ4_00\",\n",
    "\"LQ1_sb\",\n",
    "\"LQ2_ab\",\n",
    "\"AC1_yr\",\n",
    "\"MH1_yr\",\n",
    "\"EC_occp\",\n",
    "\"EC_stt_1\",\n",
    "\"EC_stt_2\",\n",
    "\"EC_wht_0\",\n",
    "\"BO1_1\",\n",
    "\"BO2_1\",\n",
    "\"BD1\",\n",
    "\"BS8_2\",\n",
    "\"BS9_2\",\n",
    "\"LW_ms\",\n",
    "\"LW_pr\",\n",
    "\"LW_oc\",\n",
    "\"HE_rPLS\",\n",
    "\"HE_Unitr\",\n",
    "\"HE_Upro\",\n",
    "\"HE_Uglu\",\n",
    "\"HE_Uket\",\n",
    "\"HE_Ubil\",\n",
    "\"HE_Ubld\",\n",
    "\"HE_Uro\",\n",
    "\"BM1_0\",\n",
    "\"BM1_1\",\n",
    "\"BM1_2\",\n",
    "\"BM1_3\",\n",
    "\"BM1_4\",\n",
    "\"BM1_5\",\n",
    "\"BM1_6\",\n",
    "\"BM1_7\",\n",
    "\"BM1_8\",\n",
    "\"L_BR_TO\",\n",
    "\"L_LN_TO\",\n",
    "\"L_DN_TO\",\n",
    "\"LK_LB_US\",\n",
    "\"LK_LB_EF\",\n",
    "\"live_t\",\n",
    "\"educ\",\n",
    "\"BO1\",\n",
    "\"HE_obe\",]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_features = [\"incm\",\n",
    "\"ho_incm\",\n",
    "\"incm5\",\n",
    "\"ho_incm5\",\n",
    "\"edu\",\n",
    "\"cfam\",\n",
    "\"house\",\n",
    "\"D_1_1\",\n",
    "\"DI3_2\",\n",
    "\"BD1_11\",\n",
    "\"BD2_1\",\n",
    "\"BA2_12\",\n",
    "\"BA2_13\",\n",
    "# \"BP1\",\n",
    "\"BS3_1\",\n",
    "\"BE3_31\",\n",
    "\"BE5_1\",\n",
    "\"OR1\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_related =[\"BP_PHQ_1\",\n",
    "\"BP_PHQ_2\",\n",
    "\"BP_PHQ_3\",\n",
    "\"BP_PHQ_4\",\n",
    "\"BP_PHQ_5\",\n",
    "\"BP_PHQ_6\",\n",
    "\"BP_PHQ_7\",\n",
    "\"BP_PHQ_8\",\n",
    "\"BP_PHQ_9\",\n",
    "\"mh_PHQ_S\",\n",
    "\"BP6_10\",\n",
    "\"BP6_31\",\n",
    "\"DF2_pr\",\n",
    "\"DF2_pt\",\n",
    "\"BP1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_origin_trn.shape)\n",
    "print(df_origin_tst.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 수동 처리\n",
    "1) 9, 99, 999 인 녀석들(모름/무응답) null 처리\n",
    "2) mh_PHQ_S 는 null값인데, 각 문항 응답인 BP_PHQ_1 ~ 9의 값이 있는 경우, 더해서 mh_PHQ_S에 넣어주기\n",
    "3) 결측값 처리 1 - row (30%) 기준\n",
    "4) 변수 생성 `depressed` == 1 if:\n",
    "    - ['mh_PHQ_S'] >= 10 or \n",
    "    - ['BP_PHQ_9'].isin([1, 2, 3]) or\n",
    "    - ['BP6_10'] == 1 or  # 1년간 자살 생각 여부\n",
    "    - ['BP6_31'] == 1 or # 1년간 자살 시도 여부\n",
    "    - ['DF2_pr'] == 1 & ['mh_PHQ_S'] == NaN # 현재 우울증으로 진단 받았지만 PHQ 설문 안 한 경우\n",
    "5) 학습에 방해가 될 수 있는 그룹 제거 (우울증에 관한 정보가 없는 경우)\n",
    "    - DF2_pr 도 null값이고, mh_PHQ_S 도 null값인 경우\n",
    "    - DF2_pr != 8 or mh_PHQ != NaN\n",
    "6) 결측값 처리 2 - column (10%) 기준  ##TODO 여기를 30%로 바꿔보기\n",
    "7) y_related 변수를 피쳐에서 제외하기\n",
    "8) 위의 결측값 처리에서 빠진 column을 각 피쳐 그룹에서 제외하기\n",
    "9) label features중 비해당(8) 값을 각각 알맞은 값으로 대체하기\n",
    "10) train column과 test column 일치시키기\n",
    "11) 각 피쳐들의 리스트를 출력해서 config에 적용하기\n",
    "------------------------------------------------------------------------------------\n",
    "여기서부턴 transform으로 처리\n",
    "1) 결측값 대체 (KNN 등)\n",
    "2) 인코딩\n",
    "3) Under, Over sampling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO \n",
    "\"\"\"DF2_pt 변수의 고려\n",
    "depressed == 0 & mh_PHQ_S != NaN & DF2_pr ==1: \n",
    "치료 여부를 파악해서 고려해주어야 함\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def manual_preprocess(df:pd.DataFrame, num_features, onehot_features, label_features, y_related):\n",
    "    # 1) 9, 99, 999 인 녀석들(모름/무응답) null 처리\n",
    "    df = df.replace([9, 99, 999, 9999], np.nan, inplace=False)\n",
    "\n",
    "    # 2) mh_PHQ_S 는 null값인데, 각 문항 응답인 BP_PHQ_1 ~ 9의 값이 있는 경우, 더해서 mh_PHQ_S에 넣어주기\n",
    "    cond = df[\"BP_PHQ_1\"].notna() & \\\n",
    "            df[\"BP_PHQ_2\"].notna() & \\\n",
    "            df[\"BP_PHQ_3\"].notna() & \\\n",
    "            df[\"BP_PHQ_4\"].notna() & \\\n",
    "            df[\"BP_PHQ_5\"].notna() & \\\n",
    "            df[\"BP_PHQ_6\"].notna() & \\\n",
    "            df[\"BP_PHQ_7\"].notna() & \\\n",
    "            df[\"BP_PHQ_8\"].notna() & \\\n",
    "            df[\"BP_PHQ_9\"].notna()\n",
    "    \n",
    "    a = df[df[\"mh_PHQ_S\"].isnull() & cond][[\"BP_PHQ_1\", \"BP_PHQ_2\", \"BP_PHQ_3\", \"BP_PHQ_4\", \"BP_PHQ_5\", \"BP_PHQ_6\", \"BP_PHQ_7\", \"BP_PHQ_8\", \"BP_PHQ_9\"]]\n",
    "    b = a[a <= 3].sum(axis=1)\n",
    "    b[b >= 1] #125\n",
    "\n",
    "    df['mh_PHQ_S'] = b[b >=1]\n",
    "\n",
    "    # 3) 결측값 처리 1 - row 기준\n",
    "    threshold = 0.3 # threshold for null proportion\n",
    "    null_percent = df.isnull().mean(axis = 1) # 각 행에 대한 결측값 비율 계산\n",
    "    df = df[null_percent < threshold]\n",
    "    \n",
    "    # 4) 변수 생성 `depressed` \n",
    "    cond1 = df['mh_PHQ_S'] >= 10 # mh_PHQ_S - total score \n",
    "    cond2 = df['BP_PHQ_9'].isin([1, 2, 3]) # person who chose 1, 2, 3 in 9th question \n",
    "    cond3 = df['BP6_10'] == 1 \n",
    "    cond4 = df['BP6_31'] == 1\n",
    "    cond5 = (df['DF2_pr'] == 1) & (df['mh_PHQ_S'].isna())\n",
    "\n",
    "    df[cond1 | cond2 | cond3 | cond4 | cond5].drop_duplicates()\n",
    " \n",
    "    df.loc[cond1 | cond2 | cond3 | cond4 | cond5, 'depressed'] = 1 # 조건 중 하나 이상을 만족하는 행에 'depressed' 변수에 1 값 \n",
    "    df.loc[~(cond1 | cond2 | cond3 | cond4 | cond5), 'depressed'] = 0 # 조건 중 하나라도 만족하지 않는 행에 0 값\n",
    "\n",
    "    # 5) 학습에 방해가 될 수 있는 그룹 제거 (우울증에 관한 정보가 없는 경우)\n",
    "    df.drop(df[df['DF2_pr'].isna() & df['mh_PHQ_S'].isna()].index, inplace=True)\n",
    "    df = df[(df['DF2_pr'] != 8 |  ~df['mh_PHQ_S'].isna())]\n",
    "\n",
    "    # 6) 결측값 처리 2 - columns 기준\n",
    "    threshold = 0.1 # 10% 기준 # TODO 30%로 바꿔보기 \n",
    "    null_percent = df.isnull().mean() # 각 열에 대한 결측값 비율 계산\n",
    "    selected_cols = null_percent[null_percent < threshold].index\n",
    "    df = df[selected_cols]\n",
    "\n",
    "    # 7) y_related 변수를 피쳐에서 제외하기\n",
    "    remained_y = set(df.columns).intersection(set(y_related))\n",
    "    y = df['depressed'] # y 생성\n",
    "    X = df.drop(columns=list(remained_y), inplace=False) # X 생성\n",
    "\n",
    "    # 8) 위의 결측값 처리에서 빠진 column을 각 피쳐 그룹에서 제외하기\n",
    "    num_features = set(df.columns).intersection(set(num_features))\n",
    "    onehot_features = set(df.columns).intersection(set(onehot_features))\n",
    "    label_features = set(df.columns).intersection(set(label_features))\n",
    "\n",
    "    # 9) label features중 비해당(8) 값을 각각 알맞은 값으로 대체하기\n",
    "    label_ans_8 = [\"DI3_2\", \"BD1_11\", \"BD2_11\", \"BA2_12\", \"BA2_13\", \"BP1\", \"BS3_1\",\"BE3_31\", \"BE5_1\"] # BD2_11 - removed\n",
    "\n",
    "    # 'DI3_2' 변수의 값이 8인 경우, 해당 값을 0으로 바꾸기\n",
    "    X['DI3_2'] = X['DI3_2'].apply(lambda x: 3 if x == 8 else x)\n",
    "    X['BD1_11'] = X['BD1_11'].apply(lambda x: 1 if x == 8 else x)\n",
    "    # X['BD2_11'] = X['BD2_11'].apply(lambda x: 0 if x == 8 else x)\n",
    "    X['BA2_12'] = X['BA2_12'].apply(lambda x: 5 if x == 8 else x)\n",
    "    X['BA2_13'] = X['BA2_13'].apply(lambda x: 5 if x == 8 else x)\n",
    "    X['BA2_13'] = X['BA2_13'].apply(lambda x: 5 if x == 8 else x)\n",
    "    # X['BP1'] = X['BP1'].apply(lambda x: 5 if x == 8 else x)\n",
    "    X['BS3_1'] = X['BS3_1'].apply(lambda x: 0 if x == 8 else x)\n",
    "    # X['BE3_31'] = X['BE3_31'].apply(lambda x: 5 if x == 88 else x)\n",
    "    # X['BE5_1'] = X['BE5_1'].apply(lambda x: 5 if x == 88 else x)\n",
    "\n",
    "    print(\"X.shape:\", X.shape)\n",
    "    print(\"y.shape:\", y.shape)\n",
    "\n",
    "    return X, y, list(num_features), list(onehot_features), list(label_features), list(y_related)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_X, trn_y, num_features, onehot_features, label_features, y_related = manual_preprocess(df_origin_trn, num_features, onehot_features, label_features, y_related)\n",
    "tst_X, tst_y, num_features, onehot_features, label_features, y_related = manual_preprocess(df_origin_tst, num_features, onehot_features, label_features, y_related)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10) train column과 test column 일치시키기\n",
    "tst_X = tst_X[list(trn_X.columns)]\n",
    "tst_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 임시 -transform\n",
    "def transform(X, y, num_features, onehot_features, label_features, y_related):\n",
    "    ### 결측값 처리 3 - fillna: KNN\n",
    "    from sklearn.impute import KNNImputer\n",
    "    from sklearn.impute import SimpleImputer\n",
    "\n",
    "    # 1) num_features 결측값 처리 - KNN\n",
    "    knn_imp = KNNImputer(n_neighbors=5)\n",
    "    X[num_features] = knn_imp.fit_transform(X[num_features])\n",
    "\n",
    "    # 2) onehot_features, label_features 결측값 처리 - 최빈값(most frequent values)\n",
    "    freq_imp = SimpleImputer(strategy = \"most_frequent\")\n",
    "    X[onehot_features] = freq_imp.fit_transform(X[onehot_features])\n",
    "    X[label_features] = freq_imp.fit_transform(X[label_features])\n",
    "\n",
    "    # transform array(X) to dataframe\n",
    "    df_new = pd.DataFrame(X, columns=X.columns) \n",
    "    df_new.isna().sum().sort_values(ascending = False)\n",
    "\n",
    "    ### 인코딩\n",
    "    # 1. numeric # 1. numeric - scaling \n",
    "    from sklearn.preprocessing import MinMaxScaler \n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    df_new[num_features] = scaler.fit_transform(df_new[num_features])\n",
    "    # 2. onehot -> onehot 인코딩으로 진행\n",
    "    df_new = pd.get_dummies(df_new, columns=onehot_features) # sklearn OneHotEncoder 사용도 가능함\n",
    "\n",
    "    ### 샘플링\n",
    "    # under sampling.  OVER 만 하기엔 너무 많이 생성해야해서 under 선수행\n",
    "    from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "    X = df_new\n",
    "    rus = RandomUnderSampler(sampling_strategy=0.5, random_state=42) # 0.1 -> 0.5로 변경\n",
    "    X_under, y_under = rus.fit_resample(X, y)\n",
    "    X_under.shape, y_under.shape\n",
    "\n",
    "    # over sampling\n",
    "    from imblearn.over_sampling import SMOTE\n",
    "\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_over, y_over = smote.fit_resample(X_under, y_under)\n",
    "\n",
    "    X_over.shape, y_over.shape\n",
    "\n",
    "    return X_over, y_over\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_over = trn_X\n",
    "y_over = trn_y\n",
    "\n",
    "print(num_features)\n",
    "print(onehot_features)\n",
    "print(label_features)\n",
    "print(y_related)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 상황에 따라 주석처리\n",
    "X_over, y_over = transform(trn_X, trn_y, list(num_features), list(onehot_features), list(label_features), list(y_related))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_over.shape, y_over.shape # ((26852, 220), (26852,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_over.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_over.to_csv('../data/HN_X_231206.csv', index=False)\n",
    "# y_over.to_csv('../data/HN_y_231206.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# 관심 있는 특성 선택\n",
    "selected_features = num_features + label_features\n",
    "\n",
    "# 선택된 특성에 대한 히스토그램\n",
    "for feature in selected_features:\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    sns.histplot(X_over[feature], kde=True)\n",
    "    plt.title(f'Distribution of {feature}')\n",
    "    plt.xlabel(feature)\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# PCA를 사용하여 차원 축소 (예: 2차원으로 축소)\n",
    "pca = PCA(n_components=2)\n",
    "train_X_pca = pca.fit_transform(X_over)\n",
    "\n",
    "# 축소된 차원의 데이터 시각화\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(x=train_X_pca[:, 0], y=train_X_pca[:, 1], hue=y_over)\n",
    "plt.xlabel('PCA1')\n",
    "plt.ylabel('PCA2')\n",
    "plt.title('PCA of Features with Labels')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# t-SNE를 사용하여 차원 축소\n",
    "tsne = TSNE(n_components=2, random_state=0)\n",
    "train_X_tsne = tsne.fit_transform(X_over)\n",
    "\n",
    "# 축소된 차원의 데이터 시각화\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(x=train_X_tsne[:, 0], y=train_X_tsne[:, 1], hue=y_over)\n",
    "plt.xlabel('t-SNE1')\n",
    "plt.ylabel('t-SNE2')\n",
    "plt.title('t-SNE of Features with Labels')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
